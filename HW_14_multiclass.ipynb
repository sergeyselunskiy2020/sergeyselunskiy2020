{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1125e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edcf29",
   "metadata": {},
   "source": [
    "Мы будем работать с данными агрегатора такси [Sigma Cabs](https://www.kaggle.com/datasets/arashnic/taxi-pricing-with-mobility-analytics). В зависимости от характеристик поездки требуется предсказать один из трех типов повышенного ценообразования: [1, 2, 3]. Таким образом, это поможет компании оптимально мэтчить такси и клиентов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e644e4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sigma_cabs.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3aa89a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Type_of_Cab</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Confidence_Life_Style_Index</th>\n",
       "      <th>Destination_Type</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T0005689460</th>\n",
       "      <td>6.77</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.42769</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>3.90500</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689461</th>\n",
       "      <td>29.47</td>\n",
       "      <td>B</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.78245</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45000</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689464</th>\n",
       "      <td>41.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>3.50125</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689465</th>\n",
       "      <td>61.56</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45375</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>74</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689467</th>\n",
       "      <td>54.95</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.03453</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.40250</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49</td>\n",
       "      <td>102</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trip_Distance Type_of_Cab  Customer_Since_Months  \\\n",
       "Trip_ID                                                         \n",
       "T0005689460           6.77           B                    1.0   \n",
       "T0005689461          29.47           B                   10.0   \n",
       "T0005689464          41.58         NaN                   10.0   \n",
       "T0005689465          61.56           C                   10.0   \n",
       "T0005689467          54.95           C                   10.0   \n",
       "\n",
       "             Life_Style_Index Confidence_Life_Style_Index Destination_Type  \\\n",
       "Trip_ID                                                                      \n",
       "T0005689460           2.42769                           A                A   \n",
       "T0005689461           2.78245                           B                A   \n",
       "T0005689464               NaN                         NaN                E   \n",
       "T0005689465               NaN                         NaN                A   \n",
       "T0005689467           3.03453                           B                A   \n",
       "\n",
       "             Customer_Rating  Cancellation_Last_1Month  Var1  Var2  Var3  \\\n",
       "Trip_ID                                                                    \n",
       "T0005689460          3.90500                         0  40.0    46    60   \n",
       "T0005689461          3.45000                         0  38.0    56    78   \n",
       "T0005689464          3.50125                         2   NaN    56    77   \n",
       "T0005689465          3.45375                         0   NaN    52    74   \n",
       "T0005689467          3.40250                         4  51.0    49   102   \n",
       "\n",
       "             Gender  Surge_Pricing_Type  \n",
       "Trip_ID                                  \n",
       "T0005689460  Female                   2  \n",
       "T0005689461    Male                   2  \n",
       "T0005689464    Male                   2  \n",
       "T0005689465    Male                   3  \n",
       "T0005689467    Male                   2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Занесем индекс колонку\n",
    "df = df.set_index('Trip_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee031a",
   "metadata": {},
   "source": [
    "Описание признаков:\n",
    "\n",
    "1. **Trip_ID**: ID for TRIP\n",
    "2. **Trip_Distance**: The distance for the trip requested by the customer\n",
    "3. **TypeofCab**: Category of the cab requested by the customer\n",
    "4. **CustomerSinceMonths**: Customer using cab services since n months; 0 month means current month\n",
    "5. **LifeStyleIndex**: Proprietary index created by Sigma Cabs showing lifestyle of the customer based on their behaviour\n",
    "6. **ConfidenceLifeStyle_Index**: Category showing confidence on the index mentioned above\n",
    "7. **Destination_Type**: Sigma Cabs divides any destination in one of the 14 categories.\n",
    "8. **Customer_Rating**: Average of life time ratings of the customer till date\n",
    "9. **CancellationLast1Month**: Number of trips cancelled by the customer in last 1 month\n",
    "10. **Var1**, **Var2** and **Var3**: Continuous variables masked by the company. Can be used for modelling purposes\n",
    "11. **Gender**: Gender of the customer\n",
    "\n",
    "**SurgePricingType**: Target (can be of 3 types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d44e2",
   "metadata": {},
   "source": [
    "### EDA \n",
    "Заполните пропуски в вещественных признаках медианой, а в категориальных - самым популярным классом. Изобразите марицу корреляций и выведите топ5 пар самых коррелированных признаков.\n",
    "\n",
    "Так как в сумме уникальных значений различных категориальных признаков окажется не супер-много, примените `One-Hot-Encoding` для них. Не забудьте в методе `pd.get_dummies` указать параметр `drop_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eecae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "Var2                      Var3                  0.683437\n",
      "Trip_Distance             Life_Style_Index      0.468332\n",
      "Life_Style_Index          Var3                  0.303324\n",
      "Customer_Rating           Var2                  0.302968\n",
      "Trip_Distance             Var3                  0.231706\n",
      "Customer_Rating           Var3                  0.227531\n",
      "Life_Style_Index          Var2                  0.215944\n",
      "Trip_Distance             Var2                  0.200456\n",
      "Life_Style_Index          Customer_Rating       0.189165\n",
      "Cancellation_Last_1Month  Surge_Pricing_Type    0.185646\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "numeric_columns = df.loc[:,df.dtypes!=np.object].columns\n",
    "#df.loc[:,df.dtypes!=np.object].head(2)\n",
    "categorical_columns = df.loc[:,df.dtypes==np.object].columns\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "\n",
    "for col in categorical_columns:\n",
    "    most_recent = df.groupby(col).size().sort_values().index[-1]\n",
    "    df[col] = df[col].fillna(most_recent)\n",
    "    \n",
    "\n",
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(df[numeric_columns], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cardiac-richardson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in categorical_columns:\n",
    "        one_hot = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "        df = pd.concat((df.drop(col, axis=1), one_hot), axis=1)\n",
    "        \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conditional-latvia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Trip_Distance', 'Customer_Since_Months', 'Life_Style_Index',\n",
       "       'Customer_Rating', 'Cancellation_Last_1Month', 'Var1', 'Var2', 'Var3',\n",
       "       'Surge_Pricing_Type', 'Type_of_Cab_B', 'Type_of_Cab_C', 'Type_of_Cab_D',\n",
       "       'Type_of_Cab_E', 'Confidence_Life_Style_Index_B',\n",
       "       'Confidence_Life_Style_Index_C', 'Destination_Type_B',\n",
       "       'Destination_Type_C', 'Destination_Type_D', 'Destination_Type_E',\n",
       "       'Destination_Type_F', 'Destination_Type_G', 'Destination_Type_H',\n",
       "       'Destination_Type_I', 'Destination_Type_J', 'Destination_Type_K',\n",
       "       'Destination_Type_L', 'Destination_Type_M', 'Destination_Type_N',\n",
       "       'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9e7d2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c424f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdaba708",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Surge_Pricing_Type', axis=1)\n",
    "y = df['Surge_Pricing_Type']\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686c150",
   "metadata": {},
   "source": [
    "**Задание 1.** Обучите One-vs-Rest Logreg. Не забудьте в шаг добавить стандартизацию данных (через `StandardScaler`) Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg. Здесь и далее округляйте до 3 знака после запятой.\n",
    "\n",
    "Чтобы отдельно и долго не вычислять метрики, можно воспользоваться `classification_report` из `sklearn.metrics`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95ba6d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.723     0.542     0.619      5372\n",
      "           2      0.636     0.834     0.722     11349\n",
      "           3      0.741     0.571     0.645      9612\n",
      "\n",
      "    accuracy                          0.679     26333\n",
      "   macro avg      0.700     0.649     0.662     26333\n",
      "weighted avg      0.692     0.679     0.673     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#SGDClassifier(loss='log') ### max(0; 1-M)\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"one_vs_all\", OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "### Your code is here\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, pipe.predict(X_test),digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f548d",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()` из предложенных. Для лучшего набора гиперпараметров посчитайте те же самые метрики. Валидировать параметры необходимо по `accuracy`. В этот раз проведем настояющую процедуру Кросс-Валидации! \n",
    "\n",
    "Для этого в метод `fit` передадим тренировочную часть наших данных, в параметр `cv` ничего не будем передавать (по дефолту 5-fold Кросс-Валидация будет проведена), а итоговые метрики замерим на тесте!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34ce35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_all__estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'one_vs_all__estimator__C': [0.001, 0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bcc508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.68062):\n",
      "{'one_vs_all__estimator__C': 0.001, 'one_vs_all__estimator__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameter (CV score={search.best_score_:.5f}):\")\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ee138",
   "metadata": {},
   "source": [
    "Изобразите три калибровочные кривые для Logistic Classifier: 0-vs-rest, 1-vs-rest, 2-vs-rest. Хорошо ли откалиброван обученный классификатор? \n",
    "\n",
    "Заметьте, что `predict_proba` возвращает список из вероятностей для всех наших классов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3173a89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('one_vs_all',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=0.001)))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Your code is here\n",
    "pipe.set_params(one_vs_all__estimator__C=0.001, one_vs_all__estimator__penalty='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "german-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.742     0.534     0.621      5372\n",
      "           2      0.635     0.839     0.723     11349\n",
      "           3      0.742     0.576     0.649      9612\n",
      "\n",
      "    accuracy                          0.681     26333\n",
      "   macro avg      0.706     0.650     0.664     26333\n",
      "weighted avg      0.696     0.681     0.675     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_result_pipe = cross_validate(pipe, X_train, y_train, scoring='accuracy',\n",
    "                                return_train_score=True)\n",
    "\n",
    "print(classification_report(y_test, search.predict(X_test),digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480baa01",
   "metadata": {},
   "source": [
    "**Задание 2.** Обучите логистическую регрессию с гиперпараметрами из первого задания на полиномиальных признаках до 4 степени. Сравните метрики с первым заданием.\n",
    "\n",
    "\n",
    "Пример: Пусть у нас был единственный признак \n",
    "\n",
    "$$\n",
    "d_j = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "Тогда полиномиальные признаки до 4 степени от такого будут иметь вид:\n",
    "\n",
    "$$\n",
    "d_j^1 = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^2 = [1, 4, 9, 16]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^3 = [1, 8, 27, 64]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^4 = [1, 16, 81, 256]\n",
    "$$\n",
    "\n",
    "P.S. Бинарные колонки нет смысла возводить в какие-то степени, поэтому возьмем исключительно вещественные из базовых. \n",
    "\n",
    "Для этого можно воспользоваться классическим циклом (или уроком из занятия про `Sberbank Housing Market`). Положите модифицированный датасет в переменную `X_polinomial`!\n",
    "\n",
    "P.S.S Зачастую еще, создаваю полиномиальные фичи, учитывают \"пересечения\" признаков, то есть, например, из векторов признаков $d_j, d_i$ генерируют не просто новые степени $d_j^2, d_i^2, d_j^3, d_i^3...$, а еще и признаки вида $d_j \\cdot d_i, d_j^2 \\cdot d_i, d_j \\cdot d_i^2...$, но здесь ограничьтесь просто степенями!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "related-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Type_of_Cab_B</th>\n",
       "      <th>Type_of_Cab_C</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination_Type_F</th>\n",
       "      <th>Destination_Type_G</th>\n",
       "      <th>Destination_Type_H</th>\n",
       "      <th>Destination_Type_I</th>\n",
       "      <th>Destination_Type_J</th>\n",
       "      <th>Destination_Type_K</th>\n",
       "      <th>Destination_Type_L</th>\n",
       "      <th>Destination_Type_M</th>\n",
       "      <th>Destination_Type_N</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "      <td>131662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.200909</td>\n",
       "      <td>6.015912</td>\n",
       "      <td>2.801448</td>\n",
       "      <td>2.849458</td>\n",
       "      <td>0.782838</td>\n",
       "      <td>62.474883</td>\n",
       "      <td>51.202800</td>\n",
       "      <td>75.099019</td>\n",
       "      <td>0.389983</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.713190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.522882</td>\n",
       "      <td>3.544411</td>\n",
       "      <td>0.207765</td>\n",
       "      <td>0.980675</td>\n",
       "      <td>1.037559</td>\n",
       "      <td>14.893324</td>\n",
       "      <td>4.986142</td>\n",
       "      <td>11.578278</td>\n",
       "      <td>0.487748</td>\n",
       "      <td>0.409844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120795</td>\n",
       "      <td>0.105742</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.078338</td>\n",
       "      <td>0.072463</td>\n",
       "      <td>0.071681</td>\n",
       "      <td>0.069713</td>\n",
       "      <td>0.026568</td>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.452274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.596380</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.580000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.687952</td>\n",
       "      <td>2.152500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.798050</td>\n",
       "      <td>2.895000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.730000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.912815</td>\n",
       "      <td>3.582500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.230000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.875110</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Trip_Distance  Customer_Since_Months  Life_Style_Index  \\\n",
       "count  131662.000000          131662.000000     131662.000000   \n",
       "mean       44.200909               6.015912          2.801448   \n",
       "std        25.522882               3.544411          0.207765   \n",
       "min         0.310000               0.000000          1.596380   \n",
       "25%        24.580000               3.000000          2.687952   \n",
       "50%        38.200000               6.000000          2.798050   \n",
       "75%        60.730000              10.000000          2.912815   \n",
       "max       109.230000              10.000000          4.875110   \n",
       "\n",
       "       Customer_Rating  Cancellation_Last_1Month           Var1  \\\n",
       "count    131662.000000             131662.000000  131662.000000   \n",
       "mean          2.849458                  0.782838      62.474883   \n",
       "std           0.980675                  1.037559      14.893324   \n",
       "min           0.001250                  0.000000      30.000000   \n",
       "25%           2.152500                  0.000000      61.000000   \n",
       "50%           2.895000                  0.000000      61.000000   \n",
       "75%           3.582500                  1.000000      61.000000   \n",
       "max           5.000000                  8.000000     210.000000   \n",
       "\n",
       "                Var2           Var3  Type_of_Cab_B  Type_of_Cab_C  ...  \\\n",
       "count  131662.000000  131662.000000  131662.000000  131662.000000  ...   \n",
       "mean       51.202800      75.099019       0.389983       0.213592  ...   \n",
       "std         4.986142      11.578278       0.487748       0.409844  ...   \n",
       "min        40.000000      52.000000       0.000000       0.000000  ...   \n",
       "25%        48.000000      67.000000       0.000000       0.000000  ...   \n",
       "50%        50.000000      74.000000       0.000000       0.000000  ...   \n",
       "75%        54.000000      82.000000       1.000000       0.000000  ...   \n",
       "max       124.000000     206.000000       1.000000       1.000000  ...   \n",
       "\n",
       "       Destination_Type_F  Destination_Type_G  Destination_Type_H  \\\n",
       "count       131662.000000       131662.000000       131662.000000   \n",
       "mean             0.014811            0.011309            0.009570   \n",
       "std              0.120795            0.105742            0.097357   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Destination_Type_I  Destination_Type_J  Destination_Type_K  \\\n",
       "count       131662.000000       131662.000000       131662.000000   \n",
       "mean             0.006175            0.005279            0.005165   \n",
       "std              0.078338            0.072463            0.071681   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       Destination_Type_L  Destination_Type_M  Destination_Type_N  \\\n",
       "count       131662.000000       131662.000000       131662.000000   \n",
       "mean             0.004884            0.000706            0.000744   \n",
       "std              0.069713            0.026568            0.027272   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "         Gender_Male  \n",
       "count  131662.000000  \n",
       "mean        0.713190  \n",
       "std         0.452274  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "hairy-daniel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trip_Distance',\n",
       " 'Customer_Since_Months',\n",
       " 'Life_Style_Index',\n",
       " 'Customer_Rating',\n",
       " 'Cancellation_Last_1Month',\n",
       " 'Var1',\n",
       " 'Var2',\n",
       " 'Var3']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spisok_col = []\n",
    "for col in X.columns:\n",
    "    if X[col].nunique() > 2:\n",
    "        spisok_col.append(col)\n",
    "spisok_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "intermediate-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 28)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "married-provincial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 52)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_polinomial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e45ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Создание полиномиальных признаков\n",
    "\n",
    "X_polinomial = X.copy()\n",
    "\n",
    "\n",
    "### Your code is here\n",
    "for col in spisok_col:\n",
    "    for power in [2, 3, 4]:\n",
    "        \n",
    "        to_add = (X_polinomial[col]**power).to_frame().rename({col:f\"{col}_{power}\"}, axis=1)\n",
    "        X_polinomial = pd.concat((X_polinomial, to_add), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efd70952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pol_train, X_pol_test, y_train, y_test  = train_test_split(X_polinomial, y, \n",
    "                                                             test_size=0.2, \n",
    "                                                             shuffle=True, \n",
    "                                                             random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1e70af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.748     0.532     0.622      5372\n",
      "           2      0.636     0.837     0.723     11349\n",
      "           3      0.741     0.584     0.653      9612\n",
      "\n",
      "    accuracy                          0.682     26333\n",
      "   macro avg      0.708     0.651     0.666     26333\n",
      "weighted avg      0.697     0.682     0.677     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "pipe = Pipeline([(\"scaler2\", StandardScaler()),\n",
    "                 (\"one_vs_all\", OneVsRestClassifier(LogisticRegression(C=0.001, penalty='l2')))])\n",
    "\n",
    "pipe.fit(X_pol_train, y_train)\n",
    "print(classification_report(y_test, pipe.predict(X_pol_test),digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb86d15",
   "metadata": {},
   "source": [
    "По аналогии с первым заданием изобразите три калибровочные кривые. Стало ли лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc9132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n",
    "### Your code is here\n",
    "a=y_test.copy()\n",
    "a[a>1]=0\n",
    "CalibrationDisplay.from_predictions(a, search.predict_proba(X_pol_test)[:,0], n_bins=15)\n",
    "\n",
    "b=y_test.copy()\n",
    "b[b!=2]=0\n",
    "CalibrationDisplay.from_predictions(b, pipe.predict_proba(X_pol_test)[:, 1], n_bins=15)\n",
    "\n",
    "c=y_test.copy()\n",
    "c[c<3]=0\n",
    "CalibrationDisplay.from_predictions(c, pipe.predict_proba(X_pol_test)[:, 2], n_bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75439311",
   "metadata": {},
   "source": [
    "**Задание 3.** Обучите на датасете без полиномиальных признаков One-vs-One `SGDClassifier` из `sklearn.linear_model`, который использует стохастический градиентный спуск (узнаете о нем позже) и может обучать как `SVM`, так и, например, `LogReg`, если указать в качестве параметра `loss` либо `hinge`, либо `log` соответственно!\n",
    "\n",
    "Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71ad008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e75280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.737     0.524     0.612      5372\n",
      "           2      0.625     0.870     0.728     11349\n",
      "           3      0.758     0.531     0.625      9612\n",
      "\n",
      "    accuracy                          0.676     26333\n",
      "   macro avg      0.707     0.642     0.655     26333\n",
      "weighted avg      0.697     0.676     0.667     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "\n",
    "pipe_all_all = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                         (\"one_vs_one\", OneVsOneClassifier(SGDClassifier()))])\n",
    "\n",
    "pipe_all_all.fit(X_train, y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pipe_all_all.predict(X_test), labels=[1, 2, 3],digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bc003",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()`. При этом переберите всевозможные функции потерь. Таким образом, при `loss = 'hinge'`, мы обучим SVM, при `loss = 'log'` мы обучим логистическую регрессию и т.д.\n",
    "\n",
    "Используйте прием с Кросс-Валидацией при подборе параметров, как ранее, а также замерьте метрики на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6d6b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_one__estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "              'one_vs_one__estimator__penalty': ['l1', 'l2'],\n",
    "              'one_vs_one__estimator__alpha': [0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fb92796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.68120):\n",
      "{'one_vs_one__estimator__alpha': 0.1, 'one_vs_one__estimator__loss': 'modified_huber', 'one_vs_one__estimator__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "search = GridSearchCV(pipe_all_all, param_grid,scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameter (CV score={search.best_score_:.5f}):\")\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "interstate-mexico",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('one_vs_one',\n",
       "                 OneVsOneClassifier(estimator=SGDClassifier(alpha=0.1,\n",
       "                                                            loss='modified_huber')))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_all_all.set_params(one_vs_one__estimator__alpha=0.1, one_vs_one__estimator__loss='modified_huber', one_vs_one__estimator__penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "american-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.747     0.530     0.620      5372\n",
      "           2      0.631     0.846     0.723     11349\n",
      "           3      0.745     0.567     0.644      9612\n",
      "\n",
      "    accuracy                          0.680     26333\n",
      "   macro avg      0.708     0.648     0.662     26333\n",
      "weighted avg      0.697     0.680     0.673     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_result_pipe = cross_validate(pipe_all_all, X_train, y_train, scoring='accuracy',\n",
    "                                return_train_score=True)\n",
    "\n",
    "print(classification_report(y_test, search.predict(X_test),digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-bottom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f1debb",
   "metadata": {},
   "source": [
    "Можно ли однозначной сказать, какой подход оказался лучше: One-vs-Rest или One-vs-One?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
